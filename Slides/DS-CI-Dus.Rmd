---
title: "`r params$module`"  # Do NOT change this line
subtitle: "`r params$shorttitle`"  # Do NOT change this line
author: "`r params$instructor`"  # Do NOT change this line
date: "`r params$semester`"  # Do NOT change this line
params:
  module: "Why Data Scientist Should Care About Causal Inference"  # Enter HERE the name of the presentation/course/module
  semester: "4. Data Science Forum"   # Enter HERE the date/semester/term
  shorttitle: ""  # Enter HERE a subtitle/shorttitle
  foottitle: "Causal Inference"  # Enter HERE a title for footline
  instructor: "Karsten Lübke, Sebastian Sauer"  # ENTER here the presentator's/instructor's name
output:
  xaringan::moon_reader:
    includes:
      after_body: insert-logo.html
    lib_dir: libs
    css: ["footer-header.css", "xafom.css"]
    nature:
      titleSlideClass: [middle, right]
      ratio: "4:3"  # Note that currently only 4:3 format is supported
---


layout: true
  
<div class="my-header"></div>

<!-- the following lines define the header and the footer line: -->
<div class="my-footer"><span>`r params$semester`    
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;
`r params$instructor` | `r params$foottitle` </span></div> 

<div class="footer-line"></div>



```{r setup, include=FALSE}
library(emojifont)
library(knitr)

library(ggdag)


# House Price
co <- data.frame(x=c(0,0,1), y=c(1,0,0), name=c("C", "X", "Y")) 

DAG_Immo <- dagify(X ~ C,
       Y ~ X,
       Y ~ C, coords = co) %>% 
  ggdag(node_size = 20, text_size = 8, text = TRUE, text_col = "lightgray") + theme_dag_blank() +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(15, "pt"), type = "closed"))  + 
  geom_text(label = "C - Living area\nX - Bedrooms \nY - Price", 
            hjust = 1, vjust = 1,
            x = 1, y = 1, size = 7, color = "darkgrey")

# Dating
co <- data.frame(x=c(0,1,2), y=c(1,0,1), name=c("Y","C","X"))

DAG_Date <- dagify(C ~ Y,
                  C ~ X, coords = co) %>% 
  ggdag(node_size = 20, text_size = 8, text = TRUE, text_col = "lightgray") + theme_dag_blank() +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(15, "pt"), type = "closed"))  + 
  geom_text(label = "Y - Looking\nX - Kindness\nC - Date",
            hjust = 0.5, vjust = 1,
            x = 1, y = 1, size = 7, color = "darkgrey")

library(mosaic)

theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)
options(scipen=999)
```


---

class: center, inverse, middle

# Data Science aims at turning raw data into understanding, insight, knowledge and to help people make better decisions.


---

## Survey: Inference from data analysis


A (very) short survey: [https://bit.ly/30sJNbm](https://bit.ly/30sJNbm)



```{r echo=FALSE, out.width = "40%", fig.align="center"}
include_graphics("img/Inferenz.jpg")
```


---

class: center, inverse, middle

# First Example: Bedrooms and house price


---

## Saratoga Houses

Data on houses in Saratoga County, New York, USA in 2006. Analysis in `R`:

```{r SaratogaSP, out.width = "35%", fig.align="center"}
# Load library
library(mosaic)
# Read in data 
data(SaratogaHouses)
# Scatterplot
gf_point(price ~ bedrooms, data = SaratogaHouses) %>%
  gf_lm(interval = "prediction")
```


---

## Modelling value of my 2-bedroom house

Linear Model: ${\text{price}}_i = {\beta}_0 + {\beta}_{\text{bedrooms}} \times \text{bedrooms}_i + \epsilon_i$:

```{r}
# Linear Regression
my.model <- lm(price ~ bedrooms, data = SaratogaHouses); my.model 
```

So: $\hat{\beta}_{\text{bedrooms}}=`r round(coef(my.model)[2],2)`$

--

```{r}
# My house: 2 bedrooms; Point prediction
My.House <- data.frame(bedrooms = 2); predict(my.model, newdata = My.House)
```

$$\widehat{\text{price}}^{|\text{bedrooms}=2} \approx `r round(predict(my.model, newdata = My.House))`$$


---

## Turn data into money

```{r, echo= FALSE , out.width = "15%", fig.align="center"}
ggplot() + geom_emoji("money_mouth_face") + theme_void()
```

Split one bedroom into three!

--

```{r}
# My rebuilt house: now 4 bedrooms
My.NewHouse <- data.frame(bedrooms = 4)
# My money (?)
predict(my.model, newdata = My.NewHouse) - predict(my.model, newdata = My.House)
```

So:

$$\widehat{\text{price}}^{|\text{bedrooms}=4} - \widehat{\text{price}}^{|\text{bedrooms}=2} = (4-2) \times \hat{\beta}_{\text{bedrooms}}=`r 2*round(coef(my.model)[2],2)`$$

---

## Really?

Make three bedrooms out of one and the value of my house goes up by $\approx 100.000$ Dollar?

--

```{r echo=FALSE, out.width = "40%", fig.align="center"}
include_graphics("img/tenor_trump.gif")
```

.small[Image Source [tenor.com](https://tenor.com/view/whatever-sarcasm-oh-well-pssh-yeah-okay-gif-4951048)]


---

## Causal Model

The number of bedrooms depends on the house size - as well as the price:

```{r echo=FALSE, out.width = "40%", fig.align="center"}
DAG_Immo
```


---

## Adjusting

Ok, let's adjust for `livingArea`:

```{r}
my.adj.model <- lm(price ~ bedrooms + livingArea, data = SaratogaHouses); my.adj.model
```

Now: $\hat{\beta}_{\text{bedrooms}}=`r round(coef(my.adj.model)[2],2)`$ (instead of $\hat{\beta}_{\text{bedrooms}}=`r round(coef(my.model)[2],2)`$ unadjusted for ` livingArea`). So: price falls instead of rises if I split a bedroom. (**Simpson's Paradox**)


<br>

--

*Hey, can't I just use e.g. `xgboost` with all variables?*


---

## Fancy machine learning method

```{r, echo= FALSE , out.width = "15%", fig.align="center"}
ggplot() + geom_emoji("thinking") + theme_void()
```

.center[*Hey, can't I just use e.g. `xgboost` with all variables?*]

.small[BTW: `mlr3`: A modern object-oriented machine learning framework in `R` ([Lang et al., 2019](https://joss.theoj.org/papers/10.21105/joss.01903))]

--

```{r, echo= FALSE , out.width = "15%", fig.align="center"}
ggplot() + geom_emoji("cry") + theme_void()
```

Unfortunately: Depending on task **not always** and quantitative measures like $MSE^{CV}$ **not always** tell you which model is best.


---

class: center, inverse, middle

# Some more words about data science


---

## Data science tasks

-  [Shmueli (2010)](https://projecteuclid.org/euclid.ss/1294167961) asked: *To Explain or to Predict?*

-  [Hernán et al. (2019)](https://doi.org/10.1080/09332480.2019.1579578) distinguished:
   - **Description**: "How can women aged 60–80 years with stroke history be partitioned in classes defined by their characteristics?"
   - **Prediction**: "What is the probability of having a stroke next year for women with certain characteristics?"
   - **Causal inference**: 	"Will starting a statin reduce, on average, the risk of stroke in women with certain characteristics?"

```{r echo=FALSE, out.width = "30%", fig.align="center"}
include_graphics("img/tenor_datamatrix.gif")
```

.small[Image Source [tenor.com](https://tenor.com/view/life-the-true-meaning-matrix-gif-5601363)]

---

## Common pitfalls

[Smith and Cordes (2019). *The 9 Pitfalls of Data Science*](https://global.oup.com/academic/product/the-9-pitfalls-of-data-science-9780198844396):

1.  Using Bad Data

2.  Putting Data Before Theory

3.  Worshipping Math

4.  Worshipping Computers

5.  Torturing Data

6.  Fooling Yourself

7.  Confusing Correlation with Causation

8.  Being Surprised by Regression Toward the Mean

9.  Doing Harm


---

## Data clown (?)

.center[<iframe width="560" height="315" align="middle" src="https://www.youtube.com/embed/uHGlCi9jOWY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>]

> But it's a shallow journey if ONLY the machine's learning


---

## Causal inference

```{r echo=FALSE, out.width = "70%", fig.align="center"}
include_graphics("img/tenor_matrix.gif")
```

.small[Image Source [tenor.com](https://tenor.com/view/the-matrix-red-pill-blue-pill-life-choices-morpheus-gif-3975355)]

--

```{r, echo= FALSE , out.width = "15%", fig.align="center"}
ggplot() + geom_emoji("thumbsup") + theme_void()
```

---

## Levels of causal inference


[Pearl (2019)](https://doi.org/10.1145/3241036) establishes a three-level hierarchy:

- **Association**: $P(y|x)$: Seeing: *what is?*, i.e., the probability of $Y=y$ given that we observe $X=x$.

- **Intervention**: $P(y|do(x))$: Manipulation: *what if?*, i.e., the probability of $Y=y$ given that we intervene and set the value of $X$ to $x$.

- **Counterfactuals**: $P(y_x|x',y')$: Imagining: *what if I had acted differently?*, i.e., the probability of $Y=y$ if $X$ had been $x$ given that we actually observed $x',y'$.

--

[Schölkopf (2019)](https://arxiv.org/abs/1911.10500):

> Graphical causal inference as pioneered by Judea Pearl arose from research on artificial intelligence (AI), and for a long time had little connection to the field of machine learning. This article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the field is beginning to understand them.

---

## One page of theory

- $X \rightarrow Y: \quad Y=f(X, U_Y)$ with some function $f(\cdot)$ and some exogenous $U$. 

- The value of $Y$ depends on $X$ - but the value of $X$ **not** on $Y$. 

- Causally there is no inverse function $f^{-1}(\cdot)$. My weight growths with my height but unfortunately my height not with my weight.

<br>



| Path                       | $X \rightarrow C \rightarrow Y$ | $X \leftarrow C \rightarrow Y$ | $X \rightarrow C \leftarrow Y$ 
| ---------------------------|---------------------------------|--------------------------------|------------------------------|
| Name                       | Chain                           | Fork                           | Collider         
| Association $X$ to $Y$     | Causal                          | Non-causal                     | None                       
| Adjusting $C$              | Blocks causal path              | Blocks non-causal path         | Opens non-causal path

<br>

Idea: Block non-causal paths, open causal paths and don't open a biasing path.


---

class: center, inverse, middle

# A first simulated example


---

## Data generating process

.pull-left[
$$ X = U_X, \quad U_X \sim \mathcal{N}(0,\,1),$$
$$Y = X +  U_Y, \quad U_Y \sim \mathcal{N}(0,\,1),$$
$$Z = Y + U_Z, \quad U_Z \sim \mathcal{N}(0,\,0.1).$$
where $\mathcal{N}(\mu,\,\sigma)$ stands for normal distribution with mean $\mu$ and variance $\sigma^2$.
]

.pull-right[
In `R`:

```{r}
set.seed(1896)
x <- rnorm(100, mean = 0, sd = 1)
y <- x + rnorm(100, mean = 0, sd = 1)
z <- y + rnorm(100, mean = 0, sd = 0.1)
```

```{r, include=FALSE}
set.seed(1896)
x <- rnorm(100)
y <- x + rnorm(100)
z <- y + rnorm(100, sd = 0.1)
Chain <- data.frame(x=x, y=y, z=z)
```
]

So **causally**: 

<br>

$$X \rightarrow Y \rightarrow Z$$

<br>

.small[Inspiration: [https://fabiandablander.com/r/Causal-Inference](https://fabiandablander.com/r/Causal-Inference)]

---

## Modelling

.center[Modelling of $y$ by $x$ or $z$]

.pull-left[
```{r, echo=FALSE, fig.align="center", out.width="90%", fig.asp = 0.8}
gf_point(y~x, data = Chain) %>% gf_lims(x=c(-6,6)) %>% gf_vline(xintercept = ~2, linetype = "dashed") %>%
  gf_lm(interval = "prediction")
```
]

.pull-right[
```{r, echo=FALSE, fig.align="center", out.width="90%", fig.asp = 0.8}
gf_point(y~z, data = Chain) %>% gf_lims(x=c(-6,6)) %>% gf_vline(xintercept = ~2, linetype = "dashed") %>%
  gf_lm(interval = "prediction")
```
]


---

## Marginal and conditional distributions (association)

.center[Marginal distribution of $y$]

```{r echo=FALSE, out.width = "30%", fig.asp = 0.8, fig.align="center"}
gf_dist("norm", params = list(sd=sqrt(2))) %>% 
  gf_labs(x="y", y="f(y)") %>% 
  gf_lims(x=c(-6,6))
```


.pull-left[
Conditional distribution of $y$, **observing** $x=2$
```{r echo=FALSE, out.width = "60%", fig.asp = 0.8, fig.align="center"}
gf_dist("norm", params = list(mean=2, sd=1)) %>% 
  gf_labs(x="y", y="f(y|x=2)") %>% 
  gf_lims(x=c(-6,6))
```
]

.pull-right[
Conditional distribution of $y$, **observing** $z=2$
```{r echo=FALSE, out.width = "60%", fig.asp = 0.8, fig.align="center"}
gf_dist("norm", params = list(mean=2, sd=0.1)) %>% 
  gf_labs(x="y", y="f(y|z=2)") %>% 
  gf_lims(x=c(-6,6))
```
]


---

## Conditional distributions (intervention)

.pull-left[
Conditional distribution of $y$, **setting** $do(x)=2$
```{r echo=FALSE, out.width = "60%", fig.asp = 0.8, fig.align="center"}
gf_dist("norm", params = list(mean=2, sd=1)) %>% 
  gf_labs(x="y", y="f(y|do(x)=2)") %>% 
  gf_lims(x=c(-6,6))
```
]

.pull-right[
Conditional distribution of $y$, **setting** $do(z)=2$
```{r echo=FALSE, out.width = "60%", fig.asp = 0.8, fig.align="center"}
gf_dist("norm", params = list(mean=0, sd=sqrt(2))) %>% 
  gf_labs(x="y", y="f(y|do(z)=2)") %>% 
  gf_lims(x=c(-6,6))
```
]

--

<br>

.center[*Sex is not love - and association is not causation*]

<br> 

--

-  In associational setting: $z$ is better for predicting $y$.

-  In interventional setting: $x$ is better for predicting $y$.

--

**How should we know this without causal assumptions?**


---

class: center, inverse, middle

# A second simulated example


---

## Dating

**Assume** you date someone because he is good looking or because he is kind. Moreover assume that looking and kindness are independent.


```{r echo=FALSE, out.width = "40%", fig.align="center"}
DAG_Date
```


---

## Data generating process

$$X = U_X, \quad U_X \sim \mathcal{N}(0,\,1),$$
$$Y = U_Y, \quad U_Y \sim \mathcal{N}(0,\,1),$$
$$\widetilde{C} =\begin{cases} 1 & ,\, \text{if } \{ X > 1 \,\vee\, Y > 1\} \\ 0 & ,\, \text{else } \end{cases},$$
$$C = (1-U_C) \cdot \widetilde{C} + U_C \cdot (1- \widetilde{C}), \quad U_C \sim \mathcal{B}(0.05).$$
where $\mathcal{B}(\pi)$ stands for the Bernoulli distribution.

In `R`:

```{r}
set.seed(1896)

kind<- rnorm(1000)
look <- rnorm(1000)
dating <- ((kind > 1) | (look > 1)) 
luck <- rbinom(1000, size = 1, prob = 0.05)
dating <- (1 - luck) * dating + luck * (1 - dating)
```

```{r, include=FALSE}
Date <- data.frame(kind, look, dating=(dating==1))
```


---

## Modelling

Modelling of `kind` by `look`, adjusted for `dating`:

```{r echo=FALSE, out.width = "50%", fig.asp = 0.8, fig.align="center"}
ggformula::gf_point(kind~look, color=~dating, data = Date) %>%
  gf_lm() + ggthemes::scale_color_colorblind()
```

--

- Adjusted for the common effect (dating) there is an association between the independent causes good looking and kindness.

- Same is true if your data consists only of those who you dated (**Berkson's Paradox**).


---

class: center, inverse, middle

# Take home messages


---

## First of all

Remember:

```{r echo=FALSE, out.width = "65%", fig.align="center"}
include_graphics("img/tenor_norris.gif")
```

.small[Image Source [tenor.com](https://tenor.com/view/chuck-norris-no-gif-9983209)]


So: Always take your anti-hubristines! 


---

## Other lessons learned - hopefully

```{r, echo= FALSE , out.width = "15%", fig.align="center"}
ggplot() + geom_emoji("woman_teacher") + theme_void()
```

To take the best action or causal conclusion based on multivariate (observational) data analysis:

- Data is not just there - it has a generating process and we should care about this.

- Confounding and Bbas can be serious issues for causal inference.

- Adjusting may be a bad idea for causal inference.

- Quantitative model checks may not reveal which model is best for causal inference.

- Structural causal models and directed acyclic graphs can help to build a bridge between reality, theory and data.


---

## Want more?

Some References:

- [Dablander, F. (2019). An introduction to Causal inference (Blogpost)](https://fabiandablander.com/r/Causal-Inference)

- [Rohrer, J.M. (2018). Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data. Advances in Methods and Practices in Psychological Science, 1(1), 27–42.](https://doi.org/10.1177/2515245917745629)
    
- [Elwert, F. (2013). Graphical causal models. In: Handbook of causal analysis for social research (S. 245-273). Springer, Dordrecht.](https://www.researchgate.net/publication/278717528_Graphical_Causal_Models)
    
- [Pearl, J., Glymour, M., & Jewell, N. P. (2016). Causal inference in statistics: A primer. John Wiley & Sons.](http://bayes.cs.ucla.edu/PRIMER/)
    
- [Peters, J., Janzing, D., & Schölkopf, B. (2017). Elements of causal inference: foundations and learning algorithms. MIT press.](https://mitpress.mit.edu/books/elements-causal-inference)

<br> 

Also:

- Causal inference is related to explainable machine learning (see e.g. [Zhao & Hastie, 2019](https://doi.org/10.1080/07350015.2019.1624293))

- Causal thinking can help to discuss algorithmic fairness (see e.g. [Kusner et al., 2017](http://papers.nips.cc/paper/6995-counterfactual-fairness))


---

## Own Work and contact

`learnr` Tutorial with real data (in German): [https://fomshinyapps.shinyapps.io/KausaleInferenz/](https://fomshinyapps.shinyapps.io/KausaleInferenz/)

- Lübke, K., Gehrke, M., Horst, J. & Szepannek, G. (2020). *Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Data*, Journal of Statistics Education (under revision).

- Lübke, K. &  Gehrke, M. (2020). *Now is the Time for Causal Inference in Introductory Statistics*, Proceedings IASE 2020 Roundtable New Skills in the Changing World of Statistics Education (submitted).

<br>

**Acknowledgement**:

We thank Matthias Gehrke, Jörg Horst and Gero Szepannek for their contributions!

```{r, echo= FALSE , out.width = "15%", fig.align="center"}
ggplot() + geom_emoji("email") + theme_void()
```

.center[[karsten.luebke@fom.de](<mailto:karsten.luebke@fom.de>)]


